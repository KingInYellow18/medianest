name: 'Performance Benchmarking - MediaNest E2E'

on:
  schedule:
    # Run performance benchmarks every 6 hours
    - cron: '0 */6 * * *'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to benchmark'
        required: false
        default: 'staging'
        type: choice
        options:
          - 'staging'
          - 'production'
      benchmark_type:
        description: 'Type of benchmarking'
        required: false
        default: 'comprehensive'
        type: choice
        options:
          - 'comprehensive'
          - 'lighthouse-only'
          - 'core-vitals'
          - 'load-testing'
  push:
    branches: [main]
    paths:
      - 'frontend/**'
      - 'backend/**'
      - 'shared/**'

env:
  NODE_VERSION: '20'
  PLAYWRIGHT_VERSION: '1.55.0'

jobs:
  setup-benchmarking:
    name: 'Setup Performance Benchmarking'
    runs-on: ubuntu-latest
    outputs:
      session-id: ${{ steps.session.outputs.id }}
      benchmark-matrix: ${{ steps.matrix.outputs.benchmarks }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci
          npx playwright install --with-deps

      - name: Initialize HIVE-MIND Performance Session
        id: session
        run: |
          cd .medianest-e2e
          SESSION_ID="perf-benchmark-$(date +%s)"
          echo "id=$SESSION_ID" >> $GITHUB_OUTPUT
          npx claude-flow@alpha swarm init --topology="hierarchical" --max-agents=6 --session-id="$SESSION_ID"
          npx claude-flow@alpha hooks pre-task --description "Performance Benchmarking: ${{ github.event.inputs.environment || 'staging' }}"

      - name: Setup benchmark matrix
        id: matrix
        run: |
          BENCHMARK_TYPE="${{ github.event.inputs.benchmark_type || 'comprehensive' }}"
          case $BENCHMARK_TYPE in
            "comprehensive")
              echo 'benchmarks=["lighthouse","core-vitals","memory-profiling","load-testing","lighthouse-ci"]' >> $GITHUB_OUTPUT
              ;;
            "lighthouse-only")
              echo 'benchmarks=["lighthouse","lighthouse-ci"]' >> $GITHUB_OUTPUT
              ;;
            "core-vitals")
              echo 'benchmarks=["core-vitals","lighthouse-ci"]' >> $GITHUB_OUTPUT
              ;;
            "load-testing")
              echo 'benchmarks=["load-testing","memory-profiling"]' >> $GITHUB_OUTPUT
              ;;
          esac

  lighthouse-benchmarking:
    name: 'Lighthouse Performance Audit'
    runs-on: ubuntu-latest
    needs: setup-benchmarking
    strategy:
      matrix:
        page: ['home', 'dashboard', 'media-browser', 'search-results', 'login', 'settings']
        device: [desktop, mobile]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci
          npx playwright install chromium

      - name: Configure environment
        run: |
          cd .medianest-e2e
          ENV="${{ github.event.inputs.environment || 'staging' }}"
          cp .env.$ENV.example .env.test
          echo "BASE_URL=${{ secrets[format('BASE_URL_{0}', github.event.inputs.environment || 'staging')] }}" >> .env.test

      - name: Run Lighthouse audit
        run: |
          cd .medianest-e2e
          npx playwright test \
            --project=performance \
            --grep="@lighthouse and @${{ matrix.page }}" \
            --reporter=json \
            --workers=1
        env:
          CI: true
          DEVICE_TYPE: ${{ matrix.device }}
          PAGE_TYPE: ${{ matrix.page }}

      - name: Process Lighthouse results
        run: |
          cd .medianest-e2e
          node scripts/process-lighthouse-results.js \
            --page=${{ matrix.page }} \
            --device=${{ matrix.device }} \
            --session-id=${{ needs.setup-benchmarking.outputs.session-id }}

      - name: Update HIVE memory
        run: |
          cd .medianest-e2e
          npx claude-flow@alpha hooks post-edit \
            --file "lighthouse-results" \
            --memory-key "perf/${{ needs.setup-benchmarking.outputs.session-id }}/lighthouse/${{ matrix.page }}/${{ matrix.device }}"

      - name: Upload Lighthouse results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: lighthouse-${{ matrix.page }}-${{ matrix.device }}
          path: |
            .medianest-e2e/reports/performance/lighthouse/
            .medianest-e2e/test-results/
          retention-days: 30

  core-vitals-benchmarking:
    name: 'Core Web Vitals Benchmarking'
    runs-on: ubuntu-latest
    needs: setup-benchmarking
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci
          npx playwright install chromium

      - name: Configure environment
        run: |
          cd .medianest-e2e
          ENV="${{ github.event.inputs.environment || 'staging' }}"
          cp .env.$ENV.example .env.test

      - name: Run Core Web Vitals tests
        run: |
          cd .medianest-e2e
          npx playwright test \
            --project=performance \
            --grep="@core-vitals" \
            --reporter=json \
            --workers=1
        env:
          CI: true

      - name: Analyze Core Web Vitals
        run: |
          cd .medianest-e2e
          node scripts/analyze-core-vitals.js \
            --session-id=${{ needs.setup-benchmarking.outputs.session-id }}

      - name: Upload Core Vitals results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: core-vitals-results
          path: |
            .medianest-e2e/reports/performance/core-vitals/
            .medianest-e2e/test-results/

  memory-profiling:
    name: 'Memory & Resource Profiling'
    runs-on: ubuntu-latest
    needs: setup-benchmarking
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci
          npx playwright install chromium

      - name: Configure environment
        run: |
          cd .medianest-e2e
          ENV="${{ github.event.inputs.environment || 'staging' }}"
          cp .env.$ENV.example .env.test

      - name: Run memory profiling tests
        run: |
          cd .medianest-e2e
          npx playwright test \
            --project=performance \
            --grep="@memory" \
            --reporter=json \
            --workers=1
        env:
          CI: true
          MEMORY_PROFILING: true

      - name: Analyze memory usage patterns
        run: |
          cd .medianest-e2e
          node scripts/analyze-memory-usage.js \
            --session-id=${{ needs.setup-benchmarking.outputs.session-id }}

      - name: Upload memory profiling results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: memory-profiling-results
          path: |
            .medianest-e2e/reports/performance/memory/
            .medianest-e2e/test-results/

  load-testing:
    name: 'Load Testing'
    runs-on: ubuntu-latest
    needs: setup-benchmarking
    strategy:
      matrix:
        load-pattern: [ramp-up, steady-state, spike, stress]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci
          npx playwright install chromium

      - name: Configure environment
        run: |
          cd .medianest-e2e
          ENV="${{ github.event.inputs.environment || 'staging' }}"
          cp .env.$ENV.example .env.test

      - name: Run load testing
        run: |
          cd .medianest-e2e
          npx playwright test \
            --project=performance \
            --grep="@load and @${{ matrix.load-pattern }}" \
            --reporter=json \
            --workers=4
        env:
          CI: true
          LOAD_PATTERN: ${{ matrix.load-pattern }}

      - name: Upload load testing results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: load-testing-${{ matrix.load-pattern }}
          path: |
            .medianest-e2e/reports/performance/load/
            .medianest-e2e/test-results/

  performance-baseline-update:
    name: 'Update Performance Baselines'
    runs-on: ubuntu-latest
    needs: [setup-benchmarking, lighthouse-benchmarking, core-vitals-benchmarking]
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Download performance artifacts
        uses: actions/download-artifact@v4
        with:
          path: .medianest-e2e/artifacts/

      - name: Update performance baselines
        run: |
          cd .medianest-e2e
          node scripts/update-performance-baselines.js \
            --session-id=${{ needs.setup-benchmarking.outputs.session-id }} \
            --branch=main \
            --commit-sha=${{ github.sha }}

      - name: Commit updated baselines
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add .medianest-e2e/reports/baselines/
          git diff --staged --quiet || git commit -m "ðŸ“Š Update performance baselines

          ðŸ¤– Generated with Claude Code

          Co-Authored-By: Claude <noreply@anthropic.com>"

      - name: Push baseline updates
        uses: ad-m/github-push-action@master
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          branch: main

  performance-analysis:
    name: 'Performance Analysis & Reporting'
    runs-on: ubuntu-latest
    needs:
      [
        setup-benchmarking,
        lighthouse-benchmarking,
        core-vitals-benchmarking,
        memory-profiling,
        load-testing,
      ]
    if: always()
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Download all performance artifacts
        uses: actions/download-artifact@v4
        with:
          path: .medianest-e2e/artifacts/

      - name: Generate comprehensive performance report
        run: |
          cd .medianest-e2e
          node scripts/generate-performance-report.js \
            --session-id=${{ needs.setup-benchmarking.outputs.session-id }} \
            --environment=${{ github.event.inputs.environment || 'staging' }} \
            --build-number=${{ github.run_number }}

      - name: Detect performance regressions
        run: |
          cd .medianest-e2e
          node scripts/detect-performance-regressions.js \
            --session-id=${{ needs.setup-benchmarking.outputs.session-id }} \
            --threshold=10

      - name: Generate performance dashboard
        run: |
          cd .medianest-e2e
          node scripts/generate-performance-dashboard.js \
            --session-id=${{ needs.setup-benchmarking.outputs.session-id }}

      - name: Upload comprehensive performance report
        uses: actions/upload-artifact@v4
        with:
          name: performance-analysis-report
          path: |
            .medianest-e2e/reports/performance/
            .medianest-e2e/dashboard/performance/
          retention-days: 90

      - name: Deploy performance dashboard
        uses: peaceiris/actions-gh-pages@v3
        if: success()
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: .medianest-e2e/dashboard/performance
          destination_dir: performance-reports/$(date +%Y%m%d)

      - name: Performance regression notification
        uses: 8398a7/action-slack@v3
        if: failure()
        with:
          status: 'failure'
          channel: '#medianest-performance'
          webhook_url: ${{ secrets.SLACK_WEBHOOK_URL }}
          custom_payload: |
            {
              "text": "ðŸš¨ Performance Regression Detected",
              "attachments": [{
                "color": "danger",
                "fields": [{
                  "title": "Environment",
                  "value": "${{ github.event.inputs.environment || 'staging' }}",
                  "short": true
                }, {
                  "title": "Build",
                  "value": "${{ github.run_number }}",
                  "short": true
                }, {
                  "title": "Dashboard",
                  "value": "https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/performance-reports/$(date +%Y%m%d)/",
                  "short": false
                }]
              }]
            }

      - name: Email performance report
        uses: dawidd6/action-send-mail@v3
        if: always()
        with:
          server_address: smtp.gmail.com
          server_port: 465
          username: ${{ secrets.EMAIL_USERNAME }}
          password: ${{ secrets.EMAIL_PASSWORD }}
          subject: 'MediaNest Performance Report - $(date +%Y-%m-%d)'
          body: file://.medianest-e2e/reports/performance/executive-summary.md
          to: ${{ secrets.PERFORMANCE_TEAM_EMAILS }}
          from: MediaNest Performance Monitor <performance@medianest.com>
          attachments: .medianest-e2e/reports/performance/comprehensive-report.pdf

      - name: Finalize HIVE session
        run: |
          cd .medianest-e2e
          npx claude-flow@alpha hooks post-task --task-id "${{ needs.setup-benchmarking.outputs.session-id }}"
          npx claude-flow@alpha hooks session-end --export-metrics true
