# MediaNest Observability Implementation Strategy

## Implementation Overview

This document provides the detailed implementation strategy for deploying comprehensive observability across the MediaNest platform. The implementation follows a phased approach, building upon existing infrastructure while introducing modern observability tools.

## Phase 1: Foundation Setup (Weeks 1-2)

### 1.1 Enhanced Metrics Collection

#### Prometheus Integration
```typescript
// backend/src/utils/metrics.ts - Enhanced version
import prometheus from 'prom-client';
import { logger } from './logger';

// Create a Registry to register the metrics
export const register = new prometheus.Registry();

// Add default metrics
prometheus.collectDefaultMetrics({
  register,
  prefix: 'medianest_',
  gcDurationBuckets: [0.001, 0.01, 0.1, 1, 2, 5]
});

// HTTP Request metrics
export const httpRequestDuration = new prometheus.Histogram({
  name: 'medianest_http_request_duration_seconds',
  help: 'Duration of HTTP requests in seconds',
  labelNames: ['method', 'endpoint', 'status_code'],
  buckets: [0.01, 0.05, 0.1, 0.3, 0.5, 1, 2, 5]
});

export const httpRequestsTotal = new prometheus.Counter({
  name: 'medianest_http_requests_total',
  help: 'Total number of HTTP requests',
  labelNames: ['method', 'endpoint', 'status_code']
});

export const activeConnections = new prometheus.Gauge({
  name: 'medianest_websocket_connections_active',
  help: 'Number of active WebSocket connections'
});

// Database metrics
export const databaseQueryDuration = new prometheus.Histogram({
  name: 'medianest_database_query_duration_seconds',
  help: 'Database query execution time',
  labelNames: ['operation', 'table', 'status'],
  buckets: [0.001, 0.01, 0.05, 0.1, 0.5, 1, 2]
});

export const databaseConnections = new prometheus.Gauge({
  name: 'medianest_database_connections_active',
  help: 'Number of active database connections'
});

// Redis metrics
export const redisOperationDuration = new prometheus.Histogram({
  name: 'medianest_redis_operation_duration_seconds',
  help: 'Redis operation execution time',
  labelNames: ['command', 'status'],
  buckets: [0.001, 0.005, 0.01, 0.05, 0.1, 0.5]
});

export const cacheHitRatio = new prometheus.Gauge({
  name: 'medianest_cache_hit_ratio',
  help: 'Cache hit ratio',
  labelNames: ['cache_type']
});

// Business metrics
export const mediaRequestsTotal = new prometheus.Counter({
  name: 'medianest_media_requests_total',
  help: 'Total number of media requests',
  labelNames: ['type', 'status', 'source']
});

export const userSessionsActive = new prometheus.Gauge({
  name: 'medianest_user_sessions_active',
  help: 'Number of active user sessions'
});

export const externalApiDuration = new prometheus.Histogram({
  name: 'medianest_external_api_duration_seconds',
  help: 'External API call duration',
  labelNames: ['service', 'operation', 'status'],
  buckets: [0.1, 0.5, 1, 2, 5, 10, 30]
});

// Circuit breaker metrics
export const circuitBreakerState = new prometheus.Gauge({
  name: 'medianest_circuit_breaker_state',
  help: 'Circuit breaker state (0=closed, 1=open, 2=half-open)',
  labelNames: ['service']
});

// Background job metrics
export const backgroundJobsTotal = new prometheus.Counter({
  name: 'medianest_background_jobs_total',
  help: 'Total number of background jobs',
  labelNames: ['queue', 'status']
});

export const backgroundJobDuration = new prometheus.Histogram({
  name: 'medianest_background_job_duration_seconds',
  help: 'Background job execution time',
  labelNames: ['queue', 'job_type'],
  buckets: [1, 5, 10, 30, 60, 300, 900]
});

// Register all metrics
register.registerMetric(httpRequestDuration);
register.registerMetric(httpRequestsTotal);
register.registerMetric(activeConnections);
register.registerMetric(databaseQueryDuration);
register.registerMetric(databaseConnections);
register.registerMetric(redisOperationDuration);
register.registerMetric(cacheHitRatio);
register.registerMetric(mediaRequestsTotal);
register.registerMetric(userSessionsActive);
register.registerMetric(externalApiDuration);
register.registerMetric(circuitBreakerState);
register.registerMetric(backgroundJobsTotal);
register.registerMetric(backgroundJobDuration);

// Export metrics function
export const getMetrics = async (): Promise<string> => {
  return register.metrics();
};
```

#### Metrics Middleware Enhancement
```typescript
// backend/src/middleware/metrics.middleware.ts
import { Request, Response, NextFunction } from 'express';
import { 
  httpRequestDuration, 
  httpRequestsTotal,
  userSessionsActive 
} from '../utils/metrics';

export const metricsMiddleware = (req: Request, res: Response, next: NextFunction) => {
  const startTime = Date.now();
  
  // Track active connections
  if (req.user?.id) {
    userSessionsActive.inc();
    
    res.on('finish', () => {
      userSessionsActive.dec();
    });
  }
  
  res.on('finish', () => {
    const duration = (Date.now() - startTime) / 1000;
    const labels = {
      method: req.method,
      endpoint: req.route?.path || req.path,
      status_code: res.statusCode.toString()
    };
    
    httpRequestDuration.observe(labels, duration);
    httpRequestsTotal.inc(labels);
  });
  
  next();
};
```

### 1.2 Infrastructure Setup

#### Docker Compose Enhancement
```yaml
# docker-compose.observability.yml
version: '3.8'

services:
  # Extend existing services
  app:
    environment:
      - PROMETHEUS_ENABLED=true
      - METRICS_PORT=9090
    ports:
      - "9090:9090"  # Metrics endpoint

  # Prometheus
  prometheus:
    image: prom/prometheus:v2.45.0
    container_name: medianest-prometheus
    restart: unless-stopped
    ports:
      - "9091:9090"
    volumes:
      - ./infrastructure/prometheus:/etc/prometheus:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=15d'
      - '--web.enable-lifecycle'
    networks:
      - medianest-network

  # Grafana
  grafana:
    image: grafana/grafana:10.1.0
    container_name: medianest-grafana
    restart: unless-stopped
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
    volumes:
      - grafana_data:/var/lib/grafana
      - ./infrastructure/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./infrastructure/grafana/dashboards:/var/lib/grafana/dashboards:ro
    networks:
      - medianest-network

  # Loki for log aggregation
  loki:
    image: grafana/loki:2.9.0
    container_name: medianest-loki
    restart: unless-stopped
    ports:
      - "3100:3100"
    volumes:
      - ./infrastructure/loki:/etc/loki:ro
      - loki_data:/loki
    command: -config.file=/etc/loki/loki-config.yml
    networks:
      - medianest-network

volumes:
  prometheus_data:
  grafana_data:
  loki_data:

networks:
  medianest-network:
    external: true
```

#### Prometheus Configuration
```yaml
# infrastructure/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'medianest-backend'
    static_configs:
      - targets: ['app:9090']
    metrics_path: '/metrics'
    scrape_interval: 10s

  - job_name: 'postgres-exporter'
    static_configs:
      - targets: ['postgres-exporter:9187']

  - job_name: 'redis-exporter'
    static_configs:
      - targets: ['redis-exporter:9121']

  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']
```

### 1.3 Enhanced Logging Integration

#### Winston Loki Transport
```typescript
// backend/src/utils/logger.ts - Enhanced version
import winston from 'winston';
import LokiTransport from 'winston-loki';

const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.errors({ stack: true }),
    winston.format.json(),
    winston.format.metadata({ fillExcept: ['message', 'level', 'timestamp'] })
  ),
  defaultMeta: { 
    service: 'medianest-backend',
    version: process.env.npm_package_version || '1.0.0',
    environment: process.env.NODE_ENV || 'development'
  },
  transports: [
    // Console transport
    new winston.transports.Console({
      format: winston.format.combine(
        winston.format.colorize(),
        winston.format.simple()
      )
    }),

    // File transport (existing)
    new DailyRotateFile({
      filename: path.join(logsDir, 'application-%DATE%.log'),
      datePattern: 'YYYY-MM-DD',
      maxSize: '20m',
      maxFiles: '14d'
    }),

    // Loki transport for log aggregation
    ...(process.env.LOKI_URL ? [
      new LokiTransport({
        host: process.env.LOKI_URL,
        labels: { 
          service: 'medianest-backend',
          environment: process.env.NODE_ENV || 'development'
        },
        json: true,
        format: winston.format.json(),
        replaceTimestamp: true,
        onConnectionError: (err) => {
          console.error('Loki connection error:', err);
        }
      })
    ] : [])
  ]
});
```

## Phase 2: Advanced Observability (Weeks 3-4)

### 2.1 Distributed Tracing Implementation

#### OpenTelemetry Setup
```typescript
// backend/src/tracing.ts
import { NodeSDK } from '@opentelemetry/sdk-node';
import { getNodeAutoInstrumentations } from '@opentelemetry/auto-instrumentations-node';
import { JaegerExporter } from '@opentelemetry/exporter-jaeger';
import { Resource } from '@opentelemetry/resources';
import { SemanticResourceAttributes } from '@opentelemetry/semantic-conventions';

const jaegerExporter = new JaegerExporter({
  endpoint: process.env.JAEGER_ENDPOINT || 'http://localhost:14268/api/traces',
});

const sdk = new NodeSDK({
  resource: new Resource({
    [SemanticResourceAttributes.SERVICE_NAME]: 'medianest-backend',
    [SemanticResourceAttributes.SERVICE_VERSION]: process.env.npm_package_version || '1.0.0',
    [SemanticResourceAttributes.DEPLOYMENT_ENVIRONMENT]: process.env.NODE_ENV || 'development',
  }),
  traceExporter: jaegerExporter,
  instrumentations: [getNodeAutoInstrumentations({
    // Disable file system instrumentation in development
    '@opentelemetry/instrumentation-fs': {
      enabled: false,
    },
  })],
});

sdk.start();

export default sdk;
```

#### Custom Instrumentation
```typescript
// backend/src/utils/tracing.ts
import { trace, SpanStatusCode, SpanKind } from '@opentelemetry/api';
import { logger } from './logger';

const tracer = trace.getTracer('medianest-backend');

export class TracingService {
  static async traceAsyncOperation<T>(
    operationName: string,
    operation: () => Promise<T>,
    attributes?: Record<string, string | number | boolean>
  ): Promise<T> {
    return tracer.startActiveSpan(operationName, async (span) => {
      try {
        if (attributes) {
          span.setAttributes(attributes);
        }
        
        const result = await operation();
        span.setStatus({ code: SpanStatusCode.OK });
        return result;
      } catch (error) {
        span.recordException(error as Error);
        span.setStatus({
          code: SpanStatusCode.ERROR,
          message: error instanceof Error ? error.message : 'Unknown error'
        });
        throw error;
      } finally {
        span.end();
      }
    });
  }

  static traceExternalApiCall<T>(
    service: string,
    operation: string,
    url: string,
    method: string,
    apiCall: () => Promise<T>
  ): Promise<T> {
    return this.traceAsyncOperation(
      `${service}.${operation}`,
      apiCall,
      {
        'http.method': method,
        'http.url': url,
        'external.service': service,
        'span.kind': SpanKind.CLIENT
      }
    );
  }

  static traceDatabaseOperation<T>(
    operation: string,
    table: string,
    query: string,
    dbOperation: () => Promise<T>
  ): Promise<T> {
    return this.traceAsyncOperation(
      `db.${operation}`,
      dbOperation,
      {
        'db.system': 'postgresql',
        'db.operation': operation,
        'db.table': table,
        'db.statement': query.substring(0, 100) // Truncate long queries
      }
    );
  }
}
```

### 2.2 Frontend Performance Monitoring

#### Web Vitals Collection
```typescript
// frontend/src/utils/performance-monitoring.ts
import { getCLS, getFCP, getFID, getLCP, getTTFB } from 'web-vitals';

interface PerformanceMetric {
  name: string;
  value: number;
  delta: number;
  id: string;
  entries: PerformanceEntry[];
}

class PerformanceMonitor {
  private metrics: Map<string, PerformanceMetric> = new Map();

  init() {
    // Collect Core Web Vitals
    getCLS(this.handleMetric.bind(this));
    getFCP(this.handleMetric.bind(this));
    getFID(this.handleMetric.bind(this));
    getLCP(this.handleMetric.bind(this));
    getTTFB(this.handleMetric.bind(this));

    // Send metrics periodically
    setInterval(() => {
      this.sendMetrics();
    }, 30000); // Every 30 seconds
  }

  private handleMetric(metric: PerformanceMetric) {
    this.metrics.set(metric.name, metric);
    
    // Log performance issues
    if (this.isPerformanceIssue(metric)) {
      console.warn(`Performance issue detected: ${metric.name} = ${metric.value}ms`);
    }
  }

  private isPerformanceIssue(metric: PerformanceMetric): boolean {
    const thresholds = {
      CLS: 0.25,    // Cumulative Layout Shift
      FCP: 3000,    // First Contentful Paint (ms)
      FID: 300,     // First Input Delay (ms)
      LCP: 4000,    // Largest Contentful Paint (ms)
      TTFB: 800     // Time to First Byte (ms)
    };

    return metric.value > (thresholds[metric.name as keyof typeof thresholds] || 0);
  }

  private async sendMetrics() {
    if (this.metrics.size === 0) return;

    const metricsData = Array.from(this.metrics.values()).map(metric => ({
      name: metric.name,
      value: metric.value,
      timestamp: Date.now(),
      url: window.location.pathname,
      userAgent: navigator.userAgent,
      connection: (navigator as any).connection?.effectiveType || 'unknown'
    }));

    try {
      await fetch('/api/v1/metrics/web-vitals', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ metrics: metricsData })
      });
    } catch (error) {
      console.error('Failed to send performance metrics:', error);
    }

    // Clear sent metrics
    this.metrics.clear();
  }

  // Custom timing measurements
  measureNavigation(fromRoute: string, toRoute: string) {
    const startTime = performance.now();
    
    return () => {
      const duration = performance.now() - startTime;
      this.sendCustomMetric('navigation_duration', duration, {
        from_route: fromRoute,
        to_route: toRoute
      });
    };
  }

  measureApiCall(endpoint: string, method: string) {
    const startTime = performance.now();
    
    return (statusCode: number) => {
      const duration = performance.now() - startTime;
      this.sendCustomMetric('api_request_duration', duration, {
        endpoint,
        method,
        status_code: statusCode.toString()
      });
    };
  }

  private async sendCustomMetric(
    name: string, 
    value: number, 
    labels: Record<string, string>
  ) {
    try {
      await fetch('/api/v1/metrics/custom', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          name,
          value,
          labels,
          timestamp: Date.now()
        })
      });
    } catch (error) {
      console.error('Failed to send custom metric:', error);
    }
  }
}

export const performanceMonitor = new PerformanceMonitor();
```

### 2.3 Business Metrics Collection

#### User Activity Tracking
```typescript
// backend/src/services/analytics.service.ts
import { 
  mediaRequestsTotal,
  userSessionsActive,
  externalApiDuration 
} from '../utils/metrics';
import { logger } from '../utils/logger';

export class AnalyticsService {
  static trackUserLogin(userId: string, loginMethod: string) {
    logger.info('User login tracked', {
      event: 'user.login.success',
      userId,
      loginMethod,
      timestamp: new Date().toISOString()
    });
    
    userSessionsActive.inc({ user_id: userId });
  }

  static trackMediaRequest(
    userId: string,
    mediaType: string,
    source: string,
    status: string
  ) {
    mediaRequestsTotal.inc({
      type: mediaType,
      status,
      source
    });

    logger.info('Media request tracked', {
      event: 'media.request.created',
      userId,
      mediaType,
      source,
      status,
      timestamp: new Date().toISOString()
    });
  }

  static trackExternalApiCall(
    service: string,
    operation: string,
    duration: number,
    status: string
  ) {
    externalApiDuration.observe(
      { service, operation, status },
      duration / 1000 // Convert to seconds
    );

    if (duration > 5000) { // Log slow API calls
      logger.warn('Slow external API call detected', {
        event: 'external.api.slow',
        service,
        operation,
        duration,
        status
      });
    }
  }

  static trackFeatureUsage(userId: string, feature: string, action: string) {
    logger.info('Feature usage tracked', {
      event: 'feature.usage',
      userId,
      feature,
      action,
      timestamp: new Date().toISOString()
    });
  }

  static trackError(
    userId: string,
    errorType: string,
    errorMessage: string,
    stackTrace?: string
  ) {
    logger.error('Application error tracked', {
      event: 'application.error',
      userId,
      errorType,
      errorMessage,
      stackTrace,
      timestamp: new Date().toISOString()
    });
  }
}
```

## Phase 3: Intelligence & Automation (Weeks 5-6)

### 3.1 Advanced Alerting Rules

#### Prometheus Alert Rules
```yaml
# infrastructure/prometheus/alert_rules.yml
groups:
  - name: medianest.rules
    rules:
      # High error rate
      - alert: HighErrorRate
        expr: |
          (
            rate(medianest_http_requests_total{status_code=~"5.."}[5m]) /
            rate(medianest_http_requests_total[5m])
          ) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} for {{ $labels.endpoint }}"

      # High response time
      - alert: HighResponseTime
        expr: |
          histogram_quantile(0.95, 
            rate(medianest_http_request_duration_seconds_bucket[5m])
          ) > 2
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }}s"

      # Database connection issues
      - alert: DatabaseConnectionHigh
        expr: medianest_database_connections_active > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High database connection usage"
          description: "Database connections: {{ $value }}"

      # Memory usage
      - alert: HighMemoryUsage
        expr: |
          (
            process_resident_memory_bytes / 
            (1024 * 1024 * 1024)
          ) > 1
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ $value | humanize }}GB"

      # External service issues
      - alert: ExternalServiceDown
        expr: medianest_circuit_breaker_state > 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "External service circuit breaker open"
          description: "Circuit breaker is open for {{ $labels.service }}"

      # Background job queue buildup
      - alert: BackgroundJobQueueBuildup
        expr: |
          rate(medianest_background_jobs_total{status="completed"}[5m]) <
          rate(medianest_background_jobs_total{status="queued"}[5m])
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Background job queue building up"
          description: "Jobs are being queued faster than processed in {{ $labels.queue }}"
```

### 3.2 Custom Dashboards

#### Main Application Dashboard
```json
{
  "dashboard": {
    "title": "MediaNest Application Overview",
    "panels": [
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(medianest_http_requests_total[5m])",
            "legendFormat": "{{method}} {{endpoint}}"
          }
        ]
      },
      {
        "title": "Response Time (95th percentile)",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(medianest_http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(medianest_http_requests_total{status_code=~\"5..\"}[5m]) / rate(medianest_http_requests_total[5m])",
            "legendFormat": "Error Rate"
          }
        ]
      },
      {
        "title": "Active Users",
        "type": "stat",
        "targets": [
          {
            "expr": "medianest_user_sessions_active",
            "legendFormat": "Active Sessions"
          }
        ]
      },
      {
        "title": "Database Performance",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(medianest_database_query_duration_seconds[5m])",
            "legendFormat": "{{operation}} {{table}}"
          }
        ]
      },
      {
        "title": "External Services Health",
        "type": "stat",
        "targets": [
          {
            "expr": "medianest_circuit_breaker_state",
            "legendFormat": "{{service}}"
          }
        ]
      }
    ]
  }
}
```

## Phase 4: Optimization & Maintenance (Weeks 7-8)

### 4.1 Performance Optimization

#### Database Query Optimization
```typescript
// backend/src/middleware/database-metrics.middleware.ts
import { PrismaClient } from '@prisma/client';
import { databaseQueryDuration } from '../utils/metrics';
import { logger } from '../utils/logger';

export function enhancePrismaWithMetrics(prisma: PrismaClient) {
  // Add query logging and metrics
  prisma.$use(async (params, next) => {
    const startTime = Date.now();
    
    try {
      const result = await next(params);
      const duration = Date.now() - startTime;
      
      // Record metrics
      databaseQueryDuration.observe(
        {
          operation: params.action,
          table: params.model || 'unknown',
          status: 'success'
        },
        duration / 1000
      );
      
      // Log slow queries
      if (duration > 1000) {
        logger.warn('Slow database query detected', {
          model: params.model,
          action: params.action,
          duration,
          args: JSON.stringify(params.args).substring(0, 500)
        });
      }
      
      return result;
    } catch (error) {
      const duration = Date.now() - startTime;
      
      databaseQueryDuration.observe(
        {
          operation: params.action,
          table: params.model || 'unknown',
          status: 'error'
        },
        duration / 1000
      );
      
      logger.error('Database query error', {
        model: params.model,
        action: params.action,
        duration,
        error: error instanceof Error ? error.message : 'Unknown error'
      });
      
      throw error;
    }
  });
  
  return prisma;
}
```

### 4.2 Automated Incident Response

#### Auto-scaling Rules
```typescript
// backend/src/services/auto-scaling.service.ts
import { CircuitBreaker } from 'opossum';
import { logger } from '../utils/logger';
import { AnalyticsService } from './analytics.service';

export class AutoScalingService {
  private static instance: AutoScalingService;
  private circuitBreakers: Map<string, CircuitBreaker> = new Map();

  static getInstance(): AutoScalingService {
    if (!AutoScalingService.instance) {
      AutoScalingService.instance = new AutoScalingService();
    }
    return AutoScalingService.instance;
  }

  // Auto-recovery for external services
  setupServiceRecovery(serviceName: string, healthCheckFn: () => Promise<boolean>) {
    const breaker = new CircuitBreaker(healthCheckFn, {
      timeout: 10000,
      errorThresholdPercentage: 50,
      resetTimeout: 30000
    });

    breaker.on('open', () => {
      logger.error(`Circuit breaker opened for ${serviceName}`);
      AnalyticsService.trackError('system', 'circuit_breaker_open', serviceName);
      
      // Trigger recovery procedures
      this.initiateServiceRecovery(serviceName);
    });

    breaker.on('halfOpen', () => {
      logger.info(`Circuit breaker half-open for ${serviceName}`);
    });

    breaker.on('close', () => {
      logger.info(`Circuit breaker closed for ${serviceName}`);
      AnalyticsService.trackFeatureUsage('system', 'service_recovery', serviceName);
    });

    this.circuitBreakers.set(serviceName, breaker);
  }

  private async initiateServiceRecovery(serviceName: string) {
    // Implement service-specific recovery logic
    switch (serviceName) {
      case 'redis':
        await this.recoverRedisConnection();
        break;
      case 'database':
        await this.recoverDatabaseConnection();
        break;
      case 'plex-api':
        await this.recoverPlexConnection();
        break;
      default:
        logger.warn(`No recovery procedure defined for ${serviceName}`);
    }
  }

  private async recoverRedisConnection() {
    // Implement Redis connection recovery
    logger.info('Attempting Redis connection recovery');
    // ... recovery logic
  }

  private async recoverDatabaseConnection() {
    // Implement database connection recovery
    logger.info('Attempting database connection recovery');
    // ... recovery logic
  }

  private async recoverPlexConnection() {
    // Implement Plex API connection recovery
    logger.info('Attempting Plex API connection recovery');
    // ... recovery logic
  }
}
```

## Deployment Scripts

### 4.3 Automated Deployment
```bash
#!/bin/bash
# scripts/deploy-observability.sh

set -e

echo "üöÄ Deploying MediaNest Observability Stack"

# Create directories
mkdir -p infrastructure/{prometheus,grafana/{provisioning,dashboards},loki}

# Start observability services
echo "üìä Starting monitoring services..."
docker-compose -f docker-compose.yml -f docker-compose.observability.yml up -d

# Wait for services to be ready
echo "‚è≥ Waiting for services to start..."
sleep 30

# Import Grafana dashboards
echo "üìà Importing Grafana dashboards..."
curl -X POST \
  http://admin:admin@localhost:3001/api/dashboards/db \
  -H 'Content-Type: application/json' \
  -d @infrastructure/grafana/dashboards/main-dashboard.json

# Verify deployment
echo "üîç Verifying deployment..."
curl -f http://localhost:9091/-/healthy || (echo "‚ùå Prometheus not healthy" && exit 1)
curl -f http://localhost:3001/api/health || (echo "‚ùå Grafana not healthy" && exit 1)
curl -f http://localhost:3100/ready || (echo "‚ùå Loki not healthy" && exit 1)

echo "‚úÖ Observability stack deployed successfully!"
echo "üåê Access Grafana at: http://localhost:3001"
echo "üìä Access Prometheus at: http://localhost:9091"
echo "üîç Application metrics at: http://localhost:9090/metrics"
```

### 4.4 Health Check Script
```bash
#!/bin/bash
# scripts/health-check.sh

echo "üè• MediaNest Health Check"

# Check application health
APP_HEALTH=$(curl -s -f http://localhost:4000/health && echo "‚úÖ Healthy" || echo "‚ùå Unhealthy")
echo "Application: $APP_HEALTH"

# Check database
DB_HEALTH=$(docker exec medianest-postgres pg_isready -U medianest && echo "‚úÖ Healthy" || echo "‚ùå Unhealthy")
echo "Database: $DB_HEALTH"

# Check Redis
REDIS_HEALTH=$(docker exec medianest-redis redis-cli ping | grep -q PONG && echo "‚úÖ Healthy" || echo "‚ùå Unhealthy")
echo "Redis: $REDIS_HEALTH"

# Check observability services
PROMETHEUS_HEALTH=$(curl -s -f http://localhost:9091/-/healthy && echo "‚úÖ Healthy" || echo "‚ùå Unhealthy")
echo "Prometheus: $PROMETHEUS_HEALTH"

GRAFANA_HEALTH=$(curl -s -f http://localhost:3001/api/health && echo "‚úÖ Healthy" || echo "‚ùå Unhealthy")
echo "Grafana: $GRAFANA_HEALTH"

LOKI_HEALTH=$(curl -s -f http://localhost:3100/ready && echo "‚úÖ Healthy" || echo "‚ùå Unhealthy")
echo "Loki: $LOKI_HEALTH"

echo ""
echo "üìä Quick Metrics Summary:"
curl -s http://localhost:9090/metrics | grep -E "medianest_(http_requests_total|user_sessions_active)" | head -5
```

## Success Metrics & KPIs

### Technical Success Metrics
- **Mean Time to Detection (MTTD)**: < 2 minutes
- **Mean Time to Resolution (MTTR)**: < 15 minutes
- **Service Availability**: 99.9% uptime
- **Alert Accuracy**: > 95% true positive rate
- **Performance Baseline**: P95 response time < 500ms

### Business Impact Metrics
- **Operational Efficiency**: 50% reduction in manual debugging time
- **User Satisfaction**: 25% reduction in user-reported issues
- **Development Velocity**: 30% faster feature delivery
- **Cost Optimization**: 20% reduction in infrastructure waste

---

*This implementation strategy provides MediaNest with production-ready observability while maintaining development velocity and operational simplicity.*